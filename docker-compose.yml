
services:
  n8n:
    image: n8nio/n8n:latest
    ports:
      - "5679:5678"
    environment:
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_PORT=5678
      - N8N_PROTOCOL=${N8N_PROTOCOL:-http}
      - NODE_ENV=production
      - WEBHOOK_URL=${N8N_WEBHOOK_URL:-http://localhost:5679/}
      - OLLAMA_HOST=http://ollama:11434
    volumes:
      - n8n_data:/home/node/.n8n
    restart: unless-stopped
    networks:
      - app-network

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11435:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    networks:
      - app-network

  openwebui:
    image: ghcr.io/open-webui/open-webui:latest
    ports:
      - "3001:8080"
    environment:
      - OLLAMA_API_BASE_URL=http://ollama:11434
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - app-network

volumes:
  n8n_data:
  ollama_data:

networks:
  app-network:
    driver: bridge
